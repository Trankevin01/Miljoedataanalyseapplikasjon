Refleksjonsnotat

Gjennom arbeidet med denne oppgaven har vi fått praktisk erfaring med hele prosessen fra datainnsamling til visualisering. 
Selv om vi hadde med oss grunnleggende kunnskap fra tidligere kurs i dataanalyse, har vi nå lært hvordan vi effektivt kan bruke 
programmering til å hente inn, behandle og analysere data. Vi har også fått en dypere forståelse for hvordan data kan struktureres, 
renses og visualiseres ved hjelp av Python og relevante biblioteker.

I løpet av prosjektet har vi tilegnet oss flere nye ferdigheter. Vi har blant annet lært å bruke klasser for å skjule API-nøkler, 
slik at de ikke er direkte tilgjengelige. Videre har vi jobbet med enhetstesting av klasser, brukt pandas i kombinasjon med 
SQL for å omforme data, og håndtert både lagring og uthenting av data fra CSV-filer. Når det gjelder visualisering, testet vi flere 
ulike verktøy og endte opp med å bruke Plotly, ettersom det ga oss best funksjonalitet og et visuelt tiltalende resultat.

Underveis støtte vi på noen utfordringer. Vi måtte blant annet bytte API på grunn av manglende historiske data. Vi startet med YR 
sitt API, men fant raskt ut at det ikke dekket våre behov. Derfor byttet vi til Frost-API, som tilbød de historiske målingene vi 
trengte. I tillegg støtte vi på problemer med manglende data fra værstasjoner. Ved forsøk på å hente ulike målinger fra samme 
geografiske område, fikk vi kun data fra én stasjon, mens andre relevante stasjoner ble ignorert. For å løse dette utviklet vi en 
funksjon som søker etter de 15 nærmeste værstasjonene og henter data der det faktisk foreligger målinger.

Samarbeidet i gruppen har fungert svært godt. Vi har jobbet tett sammen, satt konkrete mål for hver arbeidsøkt og løst oppgaver i 
fellesskap – både når det gjelder idéutvikling og implementering. I stedet for å fordele oppgaver individuelt, har vi valgt å 
samarbeide tett gjennom hele prosessen, noe som har gjort at alle har vært involvert i alle deler av prosjektet og bidratt aktivt til 
løsningene.

Sluttproduktet klarer å hente inn data fra hele Norge og visualiserer det på en oversiktlig og brukervennlig måte. I tillegg kan 
programmet gjøre en kvalifisert prediksjon av været noen dager frem i tid. Dette viser at løsningen i stor grad er tilpasset formålet. 
Det finnes likevel forbedringspotensial, spesielt når det gjelder visualiseringen og presisjonen i regresjonsmodellen, men 
helhetsinntrykket er svært positivt.

Når det gjelder selve prosjektopplegget, kunne en forbedring vært en tydeligere formidling av hva vurderingskriteriene faktisk innebar. 
Formuleringene var til tider uklare, noe som gjorde det vanskelig å vite om man skulle besvare dem gjennom koden, med kommentarer, 
i README-filen, eller om de kun fungerte som en mal for sensorens vurdering. I tillegg ville en mer oversiktlig og strukturert 
Jupyter Notebook gjort det lettere å formidle fremgangsmåten.

Det finnes også mange muligheter for videre utvikling. Man kan eksempelvis utforske andre typer applikasjoner, forbedre håndteringen 
av innsamlet data, eller ferdigstille appen og gjøre den tilgjengelig for flere brukere. En utvidelse kunne også vært å inkludere 
værdata fra flere land, noe som ville gjort løsningen mer universell og relevant på tvers av regioner.

Oppsummert har vi lært viktigheten av god filhåndtering og hvordan man bruker data fra pålitelige kilder, samtidig som vi har erfart 
hvor viktig det er å sikre at kildene faktisk tilbyr de tjenestene og dataene man trenger. Vi har også fått en dypere forståelse for 
hvor sentral dataanalyse er for å avdekke mønstre og endringer som kan få store samfunnsmessige konsekvenser.

Alt i alt har dette vært en svært nyttig øvelse, både faglig og samarbeidsmessig. Vi har fått styrket vår forståelse for programmering 
og datavitenskap, og sett tydelig hvordan slike ferdigheter er verdifulle i en stadig mer digitalisert verden. Gjennom arbeidet med 
denne oppgaven har vi fått praktisk erfaring med hele prosessen fra datainnsamling til visualisering. Selv om vi hadde med oss 
grunnleggende kunnskap fra tidligere kurs i dataanalyse, har vi nå lært hvordan vi effektivt kan bruke programmering til å hente inn, 
behandle og analysere data. Vi har også fått en dypere forståelse for hvordan data kan struktureres, renses og visualiseres ved hjelp 
av Python og relevante biblioteker. I løpet av prosjektet har vi tilegnet oss flere nye ferdigheter. Vi har blant annet lært å bruke 
klasser for å skjule API-nøkler, slik at de ikke er direkte tilgjengelige. Videre har vi jobbet med enhetstesting av klasser, brukt 
pandas i kombinasjon med SQL for å omforme data, og håndtert både lagring og uthenting av data fra CSV-filer. Når det gjelder 
visualisering, testet vi flere ulike verktøy og endte opp med å bruke Plotly, ettersom det ga oss best funksjonalitet og et visuelt 
tiltalende resultat. Underveis støtte vi på noen utfordringer. Vi måtte blant annet bytte API på grunn av manglende historiske data. 
Vi startet med YR sitt API, men fant raskt ut at det ikke dekket våre behov. Derfor byttet vi til Frost-API, som tilbød de historiske 
målingene vi trengte. I tillegg støtte vi på problemer med manglende data fra værstasjoner. Ved forsøk på å hente ulike målinger fra 
samme geografiske område, fikk vi kun data fra én stasjon, mens andre relevante stasjoner ble ignorert. For å løse dette utviklet vi 
en funksjon som søker etter de 15 nærmeste værstasjonene og henter data der det faktisk foreligger målinger. Samarbeidet i gruppen 
har fungert svært godt. Vi har jobbet tett sammen, satt konkrete mål for hver arbeidsøkt og løst oppgaver i fellesskap – både når det 
gjelder idéutvikling og implementering. I stedet for å fordele oppgaver individuelt, har vi valgt å samarbeide tett gjennom hele 
prosessen, noe som har gjort at alle har vært involvert i alle deler av prosjektet og bidratt aktivt til løsningene. Sluttproduktet 
klarer å hente inn data fra hele Norge og visualiserer det på en oversiktlig og brukervennlig måte. I tillegg kan programmet gjøre en 
kvalifisert prediksjon av været noen dager frem i tid. Dette viser at løsningen i stor grad er tilpasset formålet. Det finnes likevel 
forbedringspotensial, spesielt når det gjelder visualiseringen og presisjonen i regresjonsmodellen, men helhetsinntrykket er svært 
positivt. Når det gjelder selve prosjektopplegget, kunne en forbedring vært en tydeligere formidling av hva vurderingskriteriene 
faktisk innebar. Formuleringene var til tider uklare, noe som gjorde det vanskelig å vite om man skulle besvare dem gjennom koden, 
med kommentarer, i README-filen, eller om de kun fungerte som en mal for sensorens vurdering. I tillegg ville en mer oversiktlig og 
strukturert Jupyter Notebook gjort det lettere å formidle fremgangsmåten. Det finnes også mange muligheter for videre utvikling. Man 
kan eksempelvis utforske andre typer applikasjoner, forbedre håndteringen av innsamlet data, eller ferdigstille appen og gjøre den 
tilgjengelig for flere brukere. En utvidelse kunne også vært å inkludere værdata fra flere land, noe som ville gjort løsningen mer 
universell og relevant på tvers av regioner. Oppsummert har vi lært viktigheten av god filhåndtering og hvordan man bruker data fra 
pålitelige kilder, samtidig som vi har erfart hvor viktig det er å sikre at kildene faktisk tilbyr de tjenestene og dataene man 
trenger. Vi har også fått en dypere forståelse for hvor sentral dataanalyse er for å avdekke mønstre og endringer som kan få store 
samfunnsmessige konsekvenser. Alt i alt har dette vært en svært nyttig øvelse, både faglig og samarbeidsmessig. Vi har fått styrket 
vår forståelse for programmering og datavitenskap, og sett tydelig hvordan slike ferdigheter er verdifulle i en stadig mer 
digitalisert verden.
